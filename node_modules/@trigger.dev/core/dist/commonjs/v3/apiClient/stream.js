"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.LineTransformStream = void 0;
exports.zodShapeStream = zodShapeStream;
exports.createAsyncIterableStream = createAsyncIterableStream;
exports.createAsyncIterableReadable = createAsyncIterableReadable;
const client_1 = require("@electric-sql/client");
function zodShapeStream(schema, url, options) {
    const abortController = new AbortController();
    options?.signal?.addEventListener("abort", () => {
        abortController.abort();
    }, { once: true });
    const shapeStream = new client_1.ShapeStream({
        url,
        headers: {
            ...options?.headers,
            "x-trigger-electric-version": "1.0.0-beta.1",
        },
        fetchClient: options?.fetchClient,
        signal: abortController.signal,
        onError: (e) => {
            options?.onError?.(e);
        },
    });
    const readableShape = new ReadableShapeStream(shapeStream);
    const stream = readableShape.stream.pipeThrough(new TransformStream({
        async transform(chunk, controller) {
            const result = schema.safeParse(chunk);
            if (result.success) {
                controller.enqueue(result.data);
            }
            else {
                controller.error(new Error(`Unable to parse shape: ${result.error.message}`));
            }
        },
    }));
    return {
        stream: stream,
        stop: (delay) => {
            if (delay) {
                setTimeout(() => {
                    if (abortController.signal.aborted)
                        return;
                    abortController.abort();
                }, delay);
            }
            else {
                abortController.abort();
            }
        },
    };
}
function createAsyncIterableStream(source, transformer) {
    const transformedStream = source.pipeThrough(new TransformStream(transformer));
    transformedStream[Symbol.asyncIterator] = () => {
        const reader = transformedStream.getReader();
        return {
            async next() {
                const { done, value } = await reader.read();
                return done ? { done: true, value: undefined } : { done: false, value };
            },
        };
    };
    return transformedStream;
}
function createAsyncIterableReadable(source, transformer, signal) {
    return new ReadableStream({
        async start(controller) {
            const transformedStream = source.pipeThrough(new TransformStream(transformer));
            const reader = transformedStream.getReader();
            signal.addEventListener("abort", () => {
                queueMicrotask(() => {
                    reader.cancel();
                    controller.close();
                });
            });
            while (true) {
                const { done, value } = await reader.read();
                if (done) {
                    controller.close();
                    break;
                }
                controller.enqueue(value);
            }
        },
    });
}
class ReadableShapeStream {
    #stream;
    #currentState = new Map();
    #changeStream;
    #error = false;
    #unsubscribe;
    stop() {
        this.#unsubscribe?.();
    }
    constructor(stream) {
        this.#stream = stream;
        // Create the source stream that will receive messages
        const source = new ReadableStream({
            start: (controller) => {
                this.#unsubscribe = this.#stream.subscribe((messages) => controller.enqueue(messages), this.#handleError.bind(this));
            },
        });
        // Create the transformed stream that processes messages and emits complete rows
        this.#changeStream = createAsyncIterableStream(source, {
            transform: (messages, controller) => {
                const updatedKeys = new Set();
                for (const message of messages) {
                    if ((0, client_1.isChangeMessage)(message)) {
                        const key = message.key;
                        switch (message.headers.operation) {
                            case "insert": {
                                // New row entirely
                                this.#currentState.set(key, message.value);
                                updatedKeys.add(key);
                                break;
                            }
                            case "update": {
                                // Merge updates into existing row if any, otherwise treat as new
                                const existingRow = this.#currentState.get(key);
                                const updatedRow = existingRow
                                    ? { ...existingRow, ...message.value }
                                    : message.value;
                                this.#currentState.set(key, updatedRow);
                                updatedKeys.add(key);
                                break;
                            }
                        }
                    }
                    else if ((0, client_1.isControlMessage)(message)) {
                        if (message.headers.control === "must-refetch") {
                            this.#currentState.clear();
                            this.#error = false;
                        }
                    }
                }
                // Now enqueue only one updated row per key, after all messages have been processed.
                for (const key of updatedKeys) {
                    const finalRow = this.#currentState.get(key);
                    if (finalRow) {
                        controller.enqueue(finalRow);
                    }
                }
            },
        });
    }
    get stream() {
        return this.#changeStream;
    }
    get isUpToDate() {
        return this.#stream.isUpToDate;
    }
    get lastOffset() {
        return this.#stream.lastOffset;
    }
    get handle() {
        return this.#stream.shapeHandle;
    }
    get error() {
        return this.#error;
    }
    lastSyncedAt() {
        return this.#stream.lastSyncedAt();
    }
    lastSynced() {
        return this.#stream.lastSynced();
    }
    isLoading() {
        return this.#stream.isLoading();
    }
    isConnected() {
        return this.#stream.isConnected();
    }
    #handleError(e) {
        if (e instanceof client_1.FetchError) {
            this.#error = e;
        }
    }
}
class LineTransformStream extends TransformStream {
    buffer = "";
    constructor() {
        super({
            transform: (chunk, controller) => {
                // Append the chunk to the buffer
                this.buffer += chunk;
                // Split on newlines
                const lines = this.buffer.split("\n");
                // The last element might be incomplete, hold it back in buffer
                this.buffer = lines.pop() || "";
                // Filter out empty or whitespace-only lines
                const fullLines = lines.filter((line) => line.trim().length > 0);
                // If we got any complete lines, emit them as an array
                if (fullLines.length > 0) {
                    controller.enqueue(fullLines);
                }
            },
            flush: (controller) => {
                // On stream end, if there's leftover text, emit it as a single-element array
                const trimmed = this.buffer.trim();
                if (trimmed.length > 0) {
                    controller.enqueue([trimmed]);
                }
            },
        });
    }
}
exports.LineTransformStream = LineTransformStream;
//# sourceMappingURL=stream.js.map